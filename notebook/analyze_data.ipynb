{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv \n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/filepath.yml', 'r') as f:\n",
    "    path_config = yaml.safe_load(f)\n",
    "\n",
    "dude_dir = os.path.join('..', path_config['data']['DUD-E'])\n",
    "alphafold_dir = os.path.join('..', path_config['data']['alphafold'])\n",
    "smiles_dir = os.path.join('..', path_config['data']['smiles'])\n",
    "output_dir = os.path.join('..', path_config['data']['output'])\n",
    "hist_dir = os.path.join('..', path_config['data']['hist'])\n",
    "preprocessed_dir = os.path.join('..', path_config['data']['preprocessed'])\n",
    "sample_dir = os.path.join('..', path_config['data']['samples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyze SMILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest smiles: O=S(=O)([O-])OC[C@H]1O[C@H](O[C@@H]2[C@H](O)[C@@H](O[C@@H]3[C@H](OS(=O)(=O)[O-])[C@@H](O[C@H]4[C@H](O)[C@@H](COS(=O)(=O)[O-])O[C@H](O[C@@H]5[C@H](O)[C@@H](O[C@H]6[C@H](O)[C@@H](COS(=O)(=O)[O-])O[C@H](O[C@@H]7[C@H](O)[C@@H](O[C@@H]8[C@H](OS(=O)(=O)[O-])[C@@H](O[C@H]9[C@H](O)[C@@H](COS(=O)(=O)[O-])O[C@H](O[C@@H]%10[C@H](O)[C@@H](O[C@H]%11[C@H](O)[C@@H](COS(=O)(=O)[O-])O[C@H](O[C@@H]%12[C@H](O)[C@@H](O[C@@H]%13[C@H](OS(=O)(=O)[O-])[C@@H](O)O[C@H](COS(=O)(=O)[O-])[C@H]%13OS(=O)(=O)[O-])O[C@H](COS(=O)(=O)[O-])[C@H]%12OS(=O)(=O)[O-])[C@H]%11OS(=O)(=O)[O-])O[C@H](COS(=O)(=O)[O-])[C@H]%10OS(=O)(=O)[O-])[C@H]9OS(=O)(=O)[O-])O[C@H](COS(=O)(=O)[O-])[C@H]8OS(=O)(=O)[O-])O[C@H](COS(=O)(=O)[O-])[C@H]7OS(=O)(=O)[O-])[C@H]6OS(=O)(=O)[O-])O[C@H](COS(=O)(=O)[O-])[C@H]5OS(=O)(=O)[O-])[C@H]4OS(=O)(=O)[O-])O[C@H](COS(=O)(=O)[O-])[C@H]3OS(=O)(=O)[O-])O[C@H](COS(=O)(=O)[O-])[C@H]2OS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@@H](O[C@H]2O[C@H](COS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@H](O[C@H]3O[C@H](COS(=O)(=O)[O-])[C@@H](O)[C@H](O[C@H]4O[C@H](COS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@H](O[C@H]5O[C@H](COS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@H](O[C@H]6O[C@H](COS(=O)(=O)[O-])[C@@H](O)[C@H](O[C@H]7O[C@H](COS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@H](O[C@H]8O[C@H](COS(=O)(=O)[O-])[C@@H](O)[C@H](O[C@H]9O[C@H](COS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@H](O[C@H]%10O[C@H](COS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@H](O[C@H]%11O[C@H](COS(=O)(=O)[O-])[C@@H](O)[C@H](O[C@H]%12O[C@H](COS(=O)(=O)[O-])[C@@H](OS(=O)(=O)[O-])[C@H](O[C@H]%13O[C@H](COS(=O)(=O)[O-])[C@@H](O)C[C@@H]%13OS(=O)(=O)[O-])[C@@H]%12O)[C@@H]%11OS(=O)(=O)[O-])[C@@H]%10O)[C@@H]9OS(=O)(=O)[O-])[C@@H]8OS(=O)(=O)[O-])[C@@H]7O)[C@@H]6OS(=O)(=O)[O-])[C@@H]5O)[C@@H]4OS(=O)(=O)[O-])[C@@H]3OS(=O)(=O)[O-])[C@@H]2O)[C@@H]1O.[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+].[Na+]\n",
      "longest smiles length: 2093\n",
      "longest smiles id: CHEMBL5273238\n"
     ]
    }
   ],
   "source": [
    "smiles_csv_path = os.path.join('..',path_config['data']['train'], 'chembl_35_train.csv')\n",
    "\n",
    "active_count = 0\n",
    "decoy_count = 0\n",
    "longest_smiles = ''\n",
    "longest_smiles_len = 0\n",
    "longest_smiles_id = ''\n",
    "\n",
    "with open(smiles_csv_path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row['canonical_smiles']) > len(longest_smiles):\n",
    "            longest_smiles = row['canonical_smiles']\n",
    "            longest_smiles_len = len(row['canonical_smiles'])\n",
    "            longest_smiles_id = row['chembl_id']\n",
    "\n",
    "# print(f'Active: {active_count}')\n",
    "# print(f'Decoy: {decoy_count}')\n",
    "# print(f'total: {active_count + decoy_count}')\n",
    "print(f'longest smiles: {longest_smiles}')\n",
    "print(f'longest smiles length: {longest_smiles_len}')\n",
    "print(f'longest smiles id: {longest_smiles_id}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analize smiles embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "reading csv: 563066it [12:38, 742.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest smiles embedding length: 93\n",
      "longest smiles embedding id: ZINC08214804\n",
      "longest smiles: CO[C@H]1C[C@@H](O[C@@H]([C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H]([NH+](C)C)[C@@H]2O)C(C)C)[C@@H](C)C(=O)O[C@H](C)[C@H](C)[C@H](O)[C@@H](C)C(=O)[C@]2(C)CO2)O[C@@H](C)[C@H]1O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")\n",
    "model = AutoModel.from_pretrained(\"DeepChem/ChemBERTa-77M-MLM\")  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "def smiles_to_token_embeddings(smiles_list):\n",
    "    \"\"\"\n",
    "    SMILES のトークンごとの埋め込みを取得する関数。\n",
    "\n",
    "    Parameters:\n",
    "    - smiles_list: list of str\n",
    "        SMILES のリスト\n",
    "\n",
    "    Returns:\n",
    "    - token_embeddings: torch.Tensor\n",
    "        各トークンの埋め込み (Shape: (batch_size, seq_len, hidden_size))\n",
    "    - attention_mask: torch.Tensor\n",
    "        アテンションマスク (Shape: (batch_size, seq_len))\n",
    "    \"\"\"\n",
    "    # トークナイズ\n",
    "    encoded_inputs = tokenizer(smiles_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # デバイスに転送\n",
    "    input_ids = encoded_inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded_inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    # モデルに入力\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # トークンごとの埋め込みを取得\n",
    "    token_embeddings = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_size)\n",
    "    \n",
    "    return token_embeddings, attention_mask\n",
    "\n",
    "longest_smiles_embedding_len = 0\n",
    "longest_smiles_embedding_id = ''\n",
    "longest_smiles = ''\n",
    "\n",
    "with open(smiles_csv_path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in tqdm(reader, desc='reading csv'):\n",
    "        token_embedding, _ = smiles_to_token_embeddings([row['Canonical_SMILES']])\n",
    "        if token_embedding.shape[1] > longest_smiles_embedding_len:\n",
    "            longest_smiles_embedding_len = token_embedding.shape[1]\n",
    "            longest_smiles_embedding_id = row['Ligand_id']\n",
    "            longest_smiles = row['Canonical_SMILES']\n",
    "        \n",
    "print(f'longest smiles embedding length: {longest_smiles_embedding_len}')\n",
    "print(f'longest smiles embedding id: {longest_smiles_embedding_id}')\n",
    "print(f'longest smiles: {longest_smiles}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count active smiles numbers per uniprot id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa2ar P29274 1948\n",
      "aa2ar P30543 1376\n",
      "aa2ar P46616 15\n",
      "abl1 P00519 404\n",
      "abl1 P00520 7\n",
      "ace P09470 23\n",
      "ace P12821 514\n",
      "ace P12822 89\n",
      "ace P47820 207\n",
      "aces O42275 334\n",
      "aces P04058 98\n",
      "aces P21836 111\n",
      "aces P22303 979\n",
      "aces P23795 160\n",
      "aces P37136 374\n",
      "ada P00813 35\n",
      "ada P03958 0\n",
      "ada P56658 74\n",
      "ada17 O77636 334\n",
      "ada17 P78536 1111\n",
      "ada17 Q9Z1K9 7\n",
      "adrb1 P07700 0\n",
      "adrb1 P08588 559\n",
      "adrb1 P18090 108\n",
      "adrb1 P34971 3\n",
      "adrb1 Q9TT96 3\n",
      "adrb2 P04274 4\n",
      "adrb2 P07550 493\n",
      "adrb2 P10608 21\n",
      "adrb2 P18762 6\n",
      "adrb2 P54833 75\n",
      "adrb2 Q28044 37\n",
      "adrb2 Q8K4Z4 22\n",
      "akt1 P31749 587\n",
      "akt1 P31750 1\n",
      "akt2 P31751 237\n",
      "aldr P07943 125\n",
      "aldr P15121 372\n",
      "aldr P16116 74\n",
      "aldr P80276 59\n",
      "ampc P00811 34\n",
      "ampc P05364 66\n",
      "ampc P24735 19\n",
      "andr P10275 919\n",
      "andr P15207 162\n",
      "andr P19091 46\n",
      "aofb P19643 255\n",
      "aofb P27338 172\n",
      "aofb P56560 50\n",
      "aofb Q8BW75 1\n",
      "bace1 P56817 600\n",
      "braf P15056 317\n",
      "cah2 P00918 1957\n",
      "cah2 P00921 28\n",
      "cah2 P27139 2\n",
      "casp3 P42574 472\n",
      "cdk2 P24941 1326\n",
      "comt P21964 14\n",
      "comt P22734 27\n",
      "cp2c9 P11712 145\n",
      "cp3a4 P08684 303\n",
      "csf1r P07333 389\n",
      "csf1r P09581 27\n",
      "cxcr4 O08565 3\n",
      "cxcr4 P61073 43\n",
      "def P0A6K3 122\n",
      "def P68825 37\n",
      "def P96275 14\n",
      "dhi1 P16232 37\n",
      "dhi1 P28845 855\n",
      "dhi1 P50172 422\n",
      "dpp4 P14740 129\n",
      "dpp4 P22411 53\n",
      "dpp4 P27487 1958\n",
      "dpp4 P28843 58\n",
      "drd3 P19020 744\n",
      "drd3 P35462 1555\n",
      "dyr P00374 632\n",
      "dyr P00375 119\n",
      "dyr P00376 11\n",
      "dyr P00378 96\n",
      "dyr P00381 54\n",
      "dyr P07807 34\n",
      "dyr P0ABQ4 72\n",
      "dyr P16184 240\n",
      "dyr P22906 101\n",
      "dyr Q8NWQ9 2\n",
      "dyr Q920D2 328\n",
      "egfr P00533 1617\n",
      "egfr Q01279 8\n",
      "esr1 P03372 1276\n",
      "esr1 P06211 58\n",
      "esr1 P19785 6\n",
      "esr1 P49884 12\n",
      "esr2 O08537 21\n",
      "esr2 Q62986 56\n",
      "esr2 Q92731 1333\n",
      "fa10 O19045 16\n",
      "fa10 P00742 3139\n",
      "fa10 P00743 27\n",
      "fa10 Q63207 8\n",
      "fa7 P08709 305\n",
      "fabp4 P15090 47\n",
      "fak1 Q05397 101\n",
      "fgfr1 P11362 318\n",
      "fgfr1 P16092 15\n",
      "fkb1a P62942 155\n",
      "fkb1a Q62658 11\n",
      "fnta P29702 386\n",
      "fnta P29703 34\n",
      "fnta P49354 1002\n",
      "fnta Q04631 168\n",
      "fnta Q61239 78\n",
      "fpps P14324 85\n",
      "gcr P04150 951\n",
      "gcr P06536 55\n",
      "gcr P06537 17\n",
      "glcm P04062 45\n",
      "glcm P17439 10\n",
      "gria2 P19491 395\n",
      "gria2 P23819 16\n",
      "gria2 P42262 102\n",
      "grik1 P22756 74\n",
      "grik1 P39086 71\n",
      "hdac2 P56519 1\n",
      "hdac2 P70288 5\n",
      "hdac2 Q92769 410\n",
      "hdac8 Q8VH37 7\n",
      "hdac8 Q9BY41 314\n",
      "hivint Q7ZJM1 185\n",
      "hivpr Q72874 1511\n",
      "hivrt Q72547 1201\n",
      "hmdh P04035 143\n",
      "hmdh P51639 460\n",
      "hmdh Q01237 4\n",
      "hs90a P07900 86\n",
      "hs90a P07901 10\n",
      "hxk4 P17712 4\n",
      "hxk4 P35557 141\n",
      "igf1r P08069 373\n",
      "igf1r P24062 1\n",
      "igf1r Q60751 17\n",
      "inha P0A5Y6 44\n",
      "ital P20701 324\n",
      "ital P24063 2\n",
      "jak2 O60674 252\n",
      "kif11 P52732 276\n",
      "kit P10721 379\n",
      "kith P04183 12\n",
      "kith P06479 48\n",
      "kith Q9PPP5 0\n",
      "kpcb P05771 274\n",
      "kpcb P68403 113\n",
      "kpcb P68404 6\n",
      "lck P06239 891\n",
      "lck P06240 54\n",
      "lkha4 P09960 309\n",
      "lkha4 P19602 37\n",
      "lkha4 P24527 28\n",
      "lkha4 P30349 1\n",
      "mapk2 P49137 184\n",
      "mcr P08235 212\n",
      "mcr P22199 8\n",
      "met P08581 336\n",
      "met P16056 1\n",
      "mk01 P28482 80\n",
      "mk01 P63086 1\n",
      "mk10 P49187 36\n",
      "mk10 P53779 176\n",
      "mk14 P47811 193\n",
      "mk14 P70618 44\n",
      "mk14 Q16539 2075\n",
      "mmp13 O77656 43\n",
      "mmp13 P23097 12\n",
      "mmp13 P45452 1615\n",
      "mp2k1 P31938 1\n",
      "mp2k1 Q02750 307\n",
      "nos1 P29475 247\n",
      "nos1 P29476 124\n",
      "nos1 Q9Z0J4 9\n",
      "nram P03468 175\n",
      "nram P03474 92\n",
      "pa2ga P14422 0\n",
      "pa2ga P14423 0\n",
      "pa2ga P14555 176\n",
      "pa2ga P31482 7\n",
      "parp1 P09874 1002\n",
      "parp1 P11103 22\n",
      "parp1 P18493 1\n",
      "parp1 P27008 22\n",
      "pde5a O54735 62\n",
      "pde5a O76074 822\n",
      "pde5a Q28156 147\n",
      "pgh1 O62664 64\n",
      "pgh1 P05979 70\n",
      "pgh1 P22437 28\n",
      "pgh1 P23219 289\n",
      "pgh1 Q63921 135\n",
      "pgh2 O62698 48\n",
      "pgh2 P35354 1324\n",
      "pgh2 P35355 149\n",
      "pgh2 P79208 114\n",
      "pgh2 Q05769 153\n",
      "plk1 P53350 227\n",
      "pnph P00491 190\n",
      "pnph P23492 2\n",
      "pnph P55859 70\n",
      "pnph P85973 18\n",
      "ppara P23204 50\n",
      "ppara P37230 34\n",
      "ppara Q07869 1056\n",
      "ppara Q95N78 23\n",
      "ppard P35396 29\n",
      "ppard Q03181 713\n",
      "pparg O88275 47\n",
      "pparg P37231 1199\n",
      "pparg P37238 112\n",
      "prgr P06186 29\n",
      "prgr P06401 1097\n",
      "prgr P07812 9\n",
      "ptn1 P18031 281\n",
      "ptn1 P20417 2\n",
      "ptn1 P35821 1\n",
      "pur2 P22102 41\n",
      "pur2 Q64737 16\n",
      "pygm P00489 6\n",
      "pygm P11217 77\n",
      "pyrd O35435 36\n",
      "pyrd Q02127 184\n",
      "pyrd Q63707 46\n",
      "reni P00797 397\n",
      "reni P08424 1\n",
      "reni Q9TSZ1 67\n",
      "rock1 Q13464 218\n",
      "rock1 Q63644 2\n",
      "rxra P19793 278\n",
      "rxra P28700 18\n",
      "rxra Q05343 22\n",
      "sahh P10760 9\n",
      "sahh P23526 54\n",
      "sahh P50247 5\n",
      "tgfr1 P36897 235\n",
      "thb P10828 195\n",
      "thb P18113 53\n",
      "thrb P00734 2177\n",
      "thrb P00735 129\n",
      "thrb P18292 21\n",
      "try1 P00760 180\n",
      "try1 P07477 816\n",
      "tryb1 P27435 1\n",
      "tryb1 Q02844 1\n",
      "tryb1 Q15661 221\n",
      "tysy P00469 14\n",
      "tysy P04818 226\n",
      "tysy P07607 221\n",
      "tysy P0A884 41\n",
      "tysy P45351 2\n",
      "tysy P45352 3\n",
      "urok P00749 375\n",
      "urok P04185 1\n",
      "urok P06869 2\n",
      "urok P29598 2\n",
      "vgfr2 P35918 155\n",
      "vgfr2 P35968 2289\n",
      "wee1 P30291 221\n",
      "xiap P98170 100\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('..', path_config['data']['DUD-E'], 'target_proteins.txt'), 'r') as f:\n",
    "    target_proteins = f.read().splitlines()\n",
    "\n",
    "ligand_counts = []\n",
    "\n",
    "for target in target_proteins:\n",
    "    with open(os.path.join(dude_dir, target, 'uniprot.txt'), 'r') as f:\n",
    "        uniprot_ids = f.read().strip().splitlines()\n",
    "\n",
    "    for uniprot in uniprot_ids:\n",
    "        with open(os.path.join(dude_dir, target, uniprot + '.ism'), 'r') as f:\n",
    "            num_ligands = sum(1 for line in f if line.strip())\n",
    "        \n",
    "        ligand_counts.append({'target': target, 'uniprot': uniprot, 'num_ligands': num_ligands})\n",
    "        print(f'{target} {uniprot} {num_ligands}')\n",
    "\n",
    "df = pd.DataFrame(ligand_counts)\n",
    "df.to_csv(os.path.join(output_dir, 'ligand_counts.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>158</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL257691</td>\n",
       "      <td>-13.674135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL23278</td>\n",
       "      <td>-13.429955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL66389</td>\n",
       "      <td>-13.407990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL315076</td>\n",
       "      <td>-13.234290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL84163</td>\n",
       "      <td>-13.204518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>ZINC12877080</td>\n",
       "      <td>-2.460747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>ZINC34379976</td>\n",
       "      <td>-2.306156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>ZINC39560049</td>\n",
       "      <td>-2.224630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>ZINC43743762</td>\n",
       "      <td>-2.111117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>ZINC43740560</td>\n",
       "      <td>-1.059585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          158\n",
       "0     CHEMBL257691 -13.674135\n",
       "1      CHEMBL23278 -13.429955\n",
       "2      CHEMBL66389 -13.407990\n",
       "3     CHEMBL315076 -13.234290\n",
       "4      CHEMBL84163 -13.204518\n",
       "...            ...        ...\n",
       "2710  ZINC12877080  -2.460747\n",
       "2711  ZINC34379976  -2.306156\n",
       "2712  ZINC39560049  -2.224630\n",
       "2713  ZINC43743762  -2.111117\n",
       "2714  ZINC43740560  -1.059585\n",
       "\n",
       "[2715 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_file = os.path.join(dude_dir, 'pur2', 'glide-dock_merged_best_pv.interaction')\n",
    "\n",
    "data = pd.read_csv(interaction_file, sep=',', header=None, comment='#')\n",
    "\n",
    "data.iloc[:, [0, -1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analize preprocessed ligand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".././data/preprocessed/dataset_final.csv\n",
      "total: 563066\n",
      "longest smiles: CO[C@H]1C[C@@H](O[C@@H]([C@H](C)[C@@H](O[C@@H]2O[C@@H](C)C[C@@H]([NH+](C)C)[C@@H]2O)C(C)C)[C@@H](C)C(=O)O[C@H](C)[C@H](C)[C@H](O)[C@@H](C)C(=O)[C@]2(C)CO2)O[C@@H](C)[C@H]1O\n",
      "longest smiles length: 172\n",
      "longest smiles id: ZINC08214807\n"
     ]
    }
   ],
   "source": [
    "smiles_csv_path = os.path.join(preprocessed_dir, 'dataset_final.csv')\n",
    "print(smiles_csv_path)\n",
    "longest_smiles = ''\n",
    "longest_smiles_len = 0\n",
    "longest_smiles_id = ''\n",
    "total_count = 0\n",
    "\n",
    "with open(smiles_csv_path, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        total_count += 1\n",
    "        if len(row['Canonical_SMILES']) > len(longest_smiles):\n",
    "            longest_smiles = row['Canonical_SMILES']\n",
    "            longest_smiles_len = len(row['Canonical_SMILES'])\n",
    "            longest_smiles_id = row['Ligand_id']\n",
    "\n",
    "print(f'total: {total_count}')\n",
    "print(f'longest smiles: {longest_smiles}')\n",
    "print(f'longest smiles length: {longest_smiles_len}')\n",
    "print(f'longest smiles id: {longest_smiles_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analize protein representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure.npy shape: 412\n",
      "max protein length: 1390\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(smiles_dir, 'available_uniprot.csv'))\n",
    "available_uniprot = df['UniProt ID'].tolist()\n",
    "protein_files = [os.path.join(alphafold_dir, uniprot, 'structure.npy') for uniprot in available_uniprot]\n",
    "\n",
    "print(f\"structure.npy shape: {np.load(protein_files[0]).shape[0]}\")\n",
    "\n",
    "protein_max_length = 0\n",
    "for file in protein_files:\n",
    "    if np.load(file).shape[0] > protein_max_length:\n",
    "        protein_max_length = np.load(file).shape[0]\n",
    "\n",
    "print(f\"max protein length: {protein_max_length}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atcvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
