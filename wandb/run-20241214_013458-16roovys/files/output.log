Epoch 1 / 10 Train:   0%|                                    | 0/14052 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|               | 1/14052 [00:03<14:15:31,  3.65s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 2/14052 [00:04<8:00:43,  2.05s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 3/14052 [00:05<6:01:43,  1.54s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 4/14052 [00:06<5:05:01,  1.30s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 5/14052 [00:07<4:34:50,  1.17s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 6/14052 [00:08<4:18:32,  1.10s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 7/14052 [00:09<4:07:32,  1.06s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 8/14052 [00:10<4:01:00,  1.03s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|                | 9/14052 [00:11<3:58:24,  1.02s/it, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|               | 10/14052 [00:12<3:52:13,  1.01it/s, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|               | 11/14052 [00:13<3:47:59,  1.03it/s, loss=nan]Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1 / 10 Train:   0%|               | 12/14052 [00:14<4:43:47,  1.21s/it, loss=nan]
Traceback (most recent call last):
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/scripts/train_prediction_model.py", line 126, in <module>
    train()
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/scripts/train_prediction_model.py", line 75, in train
    for _, batch in enumerate(train_pbar):
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/src/data/dataloader.py", line 22, in custom_colleate_fn
    smiles_embeddings, smiles_mask = SmilesProteinDataset.featurize_smiles_static(smiles_list, smiles_max_len=100)
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/src/data/dataset.py", line 99, in featurize_smiles_static
    tokenizer = AutoTokenizer.from_pretrained("DeepChem/ChemBERTa-77M-MLM")
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 858, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 690, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 862, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 925, in _hf_hub_download_to_cache_dir
    (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1376, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1296, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 277, in _request_wrapper
    response = _request_wrapper(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 300, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    response = conn.getresponse()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/urllib3/connection.py", line 507, in getresponse
    httplib_response = super().getresponse()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/http/client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/socket.py", line 717, in readinto
    return self._sock.recv_into(b)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/ssl.py", line 1307, in recv_into
    return self.read(nbytes, buffer)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/ssl.py", line 1163, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt
Traceback (most recent call last):
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/scripts/train_prediction_model.py", line 126, in <module>
    train()
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/scripts/train_prediction_model.py", line 75, in train
    for _, batch in enumerate(train_pbar):
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/src/data/dataloader.py", line 22, in custom_colleate_fn
    smiles_embeddings, smiles_mask = SmilesProteinDataset.featurize_smiles_static(smiles_list, smiles_max_len=100)
  File "/mnt/c/Users/rixyt/workspace_eagle/sekijima_lab_local/AttentionConditionedVAE/src/data/dataset.py", line 99, in featurize_smiles_static
    tokenizer = AutoTokenizer.from_pretrained("DeepChem/ChemBERTa-77M-MLM")
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 858, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 690, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 862, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 925, in _hf_hub_download_to_cache_dir
    (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1376, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1296, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 277, in _request_wrapper
    response = _request_wrapper(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 300, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 93, in send
    return super().send(request, *args, **kwargs)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/urllib3/connectionpool.py", line 536, in _make_request
    response = conn.getresponse()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/site-packages/urllib3/connection.py", line 507, in getresponse
    httplib_response = super().getresponse()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/http/client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/socket.py", line 717, in readinto
    return self._sock.recv_into(b)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/ssl.py", line 1307, in recv_into
    return self.read(nbytes, buffer)
  File "/home/rixyt/miniconda3/envs/atcvae/lib/python3.10/ssl.py", line 1163, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt
